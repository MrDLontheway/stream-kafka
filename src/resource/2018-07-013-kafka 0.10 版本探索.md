---
layout: post
title:  "kafka 0.10 版本探索"
date:   2018-07-08 05:00:08
tags: ["学习历程"]
categories: "Learning process"
comments: true
---
  <h1>kafka 0.10 版本探索</h1>
首先，博主之前用的spark-streaming-kafka 1.6 scala 2.10的包，当时的kafka两种连接方式 高层封装 

1.基于Receiver的方式
   简单介绍一下，这种方式可能会因为底层的失败而丢失数据。如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。
俗称WAL ，但是个人认为这是多余且不必要的操作 kafka以及做了很多的高可用，数据备份机制。那消费数据为何还需要开启WAL?  

需要注意的要点

1、Kafka中的topic的partition，与Spark中的RDD的partition是没有关系的。所以，在KafkaUtils.createStream()中，提高partition的数量，只会增加一个Receiver中，读取partition的线程的数量。不会增加Spark处理数据的并行度。

2、可以创建多个Kafka输入DStream，使用不同的consumer group和topic，来通过多个receiver并行接收数据。

3、如果基于容错的文件系统，比如HDFS，启用了预写日志机制，接收到的数据都会被复制一份到预写日志中。因此，在KafkaUtils.createStream()中，设置的持久化级别是StorageLevel.MEMORY_AND_DISK_SER。

4、receiver是额外启动 相对消耗资源，总的来说 优点不多。


2.基于Direct的方式
   用底层API直接连kafka spark partition与kafka 一一对应 增加并行度。

1、简化并行读取：如果要读取多个partition，不需要创建多个输入DStream然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在Kafka partition和RDD partition之间，有一个一对一的映射关系。

2、高性能：如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有高可靠的机制，会对数据复制一份，而这里又会复制一份到WAL中。而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。

3、一次且仅一次的事务机制：
基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中。Spark自己一定是同步的，因此可以保证数据是消费一次且仅消费一次。

kafka 数据高可用 数据高可靠性 无丢失配置  ack=-1 消费采取direct 直连 消费数据做成事物 spark 自己维护偏移量信息


之前博主采用的直连方式是写一个org.apache.spark.streaming.kafka 包下工具类 实例化KafkaCluster 然后自己封装增强 包装设计模式，后来kafka升级到0.10

spark升级到2.10后 发现之前博主的工具包报错了， 竟然连KafkaCluster KafkaManager 全部都没了，讲道理 kafka升级真的是有点小变态啊。。。。 看来
kafka也是发现了Receiver的弊端，新的包内 直接封装直连方式 自己维护偏移量
```text
KafkaUtils.createDirectStream[String, String](
                                 ssc,
                                 PreferConsistent,
                                 Subscribe[String, String](topicsSet, kafkaParams)
                               )
//维护偏移量操作
stream.foreachRDD { rdd =>
  val offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges

  // some time later, after outputs have completed
  stream.asInstanceOf[CanCommitOffsets].commitAsync(offsetRanges)
}
```

在调试集群的时候发现了一个问题目前还没找到问题的根本原因，首先博主将kafka绑定的是内网的端口，外网竟然可以访问~~ 好就算是我绑定错了 那是不是外网应该可以正常提供服务呢?
其实不然  根据调试 我用生产者从外网端口send message 的时候自动创建了topic好的 到这里都没问题 发送message的时候 竟然显示的是发送成功 没有抱任何的错误，kafka 集群也没有接收到消息，
这个问题就非常奇怪了，通过调试将jar提交到集群内跑是可以成功发送message的。还有一个就是kafka-console-producer.sh 这个工具竟然不好使。。。 kafka对我是真的不太友好 之前的版本使用都是没有问题的。

